{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.custom_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset\n",
    "> Implement a custom dataset for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import copy\n",
    "from runningpose.core.skeleton import Skeleton\n",
    "from runningpose.core.mocap_dataset import MocapDataset\n",
    "from runningpose.core.camera import normalize_screen_coordinates, image_coordinates\n",
    "from runningpose.core.h36m_dataset import h36m_skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "custom_camera_params = {\n",
    "    'id': None,\n",
    "    'res_w': None, # Pulled from metadata\n",
    "    'res_h': None, # Pulled from metadata\n",
    "    \n",
    "    # Dummy camera parameters (taken from Human3.6M), only for visualization purposes\n",
    "    'azimuth': 70, # Only used for visualization\n",
    "    'orientation': [0.1407056450843811, -0.1500701755285263, -0.755240797996521, 0.6223280429840088],\n",
    "    'translation': [1841.1070556640625, 4955.28466796875, 1563.4454345703125],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(MocapDataset):\n",
    "    \"\"\"Creates a custom dataset with the Human36m skeleton.\"\"\"\n",
    "    def __init__(self, detections_path, remove_static_joints=True):\n",
    "        super().__init__(fps=None, skeleton=h36m_skeleton)        \n",
    "        self._cameras = {}\n",
    "        self._data = {}\n",
    "\n",
    "        # Load serialized dataset\n",
    "        data = np.load(detections_path, allow_pickle=True)\n",
    "        resolutions = data['metadata'].item()['video_metadata']\n",
    "\n",
    "        for video_name, res in resolutions.items():\n",
    "            cam = {}\n",
    "            cam.update(custom_camera_params)\n",
    "            cam['orientation'] = np.array(cam['orientation'], dtype='float32')\n",
    "            cam['translation'] = np.array(cam['translation'], dtype='float32')\n",
    "            cam['translation'] = cam['translation']/1000 # mm to meters\n",
    "            \n",
    "            cam['id'] = video_name\n",
    "            cam['res_w'] = res['w']\n",
    "            cam['res_h'] = res['h']\n",
    "            \n",
    "            self._cameras[video_name] = [cam]\n",
    "        \n",
    "            self._data[video_name] = {'custom': { 'cameras': cam } }\n",
    "                \n",
    "        if remove_static_joints:\n",
    "            # Bring the skeleton to 17 joints instead of the original 32\n",
    "            self.remove_joints([4, 5, 9, 10, 11, 16, 20, 21, 22, 23, 24, 28, 29, 30, 31])\n",
    "            \n",
    "            # Rewire shoulders to the correct parents\n",
    "            self._skeleton._parents[11] = 8\n",
    "            self._skeleton._parents[14] = 8\n",
    "            \n",
    "    def supports_semi_supervised(self):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c909c460115528381e5e42942faf83c76450671048106747074a2271b38f572"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
