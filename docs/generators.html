---

title: Generators


keywords: fastai
sidebar: home_sidebar

summary: "Data generators for training and testing respectively."
description: "Data generators for training and testing respectively."
nb_path: "nbs/08_generators.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/08_generators.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ChunkedGenerator" class="doc_header"><code>class</code> <code>ChunkedGenerator</code><a href="https://github.tifx04-22-10.com/TIFX04-22-10/runningpose/tree/master/runningpose/core/generators.py#L11" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ChunkedGenerator</code>(<strong><code>batch_size</code></strong>, <strong><code>cameras</code></strong>, <strong><code>poses_3d</code></strong>, <strong><code>poses_2d</code></strong>, <strong><code>chunk_length</code></strong>, <strong><code>pad</code></strong>=<em><code>0</code></em>, <strong><code>causal_shift</code></strong>=<em><code>0</code></em>, <strong><code>shuffle</code></strong>=<em><code>True</code></em>, <strong><code>random_seed</code></strong>=<em><code>47</code></em>, <strong><code>augment</code></strong>=<em><code>False</code></em>, <strong><code>kps_left</code></strong>=<em><code>None</code></em>, <strong><code>kps_right</code></strong>=<em><code>None</code></em>, <strong><code>joints_left</code></strong>=<em><code>None</code></em>, <strong><code>joints_right</code></strong>=<em><code>None</code></em>, <strong><code>endless</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Batched data generator, used for training.
The sequences are split into equal-length chunks and padded as necessary.</p>
<p>Arguments:
batch_size -- The batch size to use for training.
cameras -- List of cameras, one element for each video
    (optional, used for semi-supervised training).</p>
<p>poses_3d -- List of ground-truth 3D poses, one element for each video
    (optional, used for supervised training).</p>
<p>poses_2d -- List of input 2D keypoints, one element for each video.</p>
<p>chunk_length -- Number of output frames to predict for each training
    example (usually 1).</p>
<p>pad -- 2D input padding to compensate for valid convolutions,
    per side (depends on the receptive field).</p>
<p>causal_shift -- Asymmetric padding offset when causal convolutions
     are used (usually 0 or "pad").
shuffle -- Randomly shuffle the dataset before each epoch.
random_seed -- Initial seed to use for the random generator.
augment -- Augment the dataset by flipping poses horizontally.</p>
<p>kps_left and kps_right -- List of left/right 2D keypoints if
    flipping is enabled.</p>
<p>joints_left and joints_right -- List of left/right 3D joints if
    flipping is enabled.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnchunkedGenerator" class="doc_header"><code>class</code> <code>UnchunkedGenerator</code><a href="https://github.tifx04-22-10.com/TIFX04-22-10/runningpose/tree/master/runningpose/core/generators.py#L218" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnchunkedGenerator</code>(<strong><code>cameras</code></strong>, <strong><code>poses_3d</code></strong>, <strong><code>poses_2d</code></strong>, <strong><code>pad</code></strong>=<em><code>0</code></em>, <strong><code>causal_shift</code></strong>=<em><code>0</code></em>, <strong><code>augment</code></strong>=<em><code>False</code></em>, <strong><code>kps_left</code></strong>=<em><code>None</code></em>, <strong><code>kps_right</code></strong>=<em><code>None</code></em>, <strong><code>joints_left</code></strong>=<em><code>None</code></em>, <strong><code>joints_right</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Non-batched data generator, used for testing.
Sequences are returned one at a time (i.e. batch size = 1),
without chunking.</p>
<p>If data augmentation is enabled, the batches contain two sequences
(i.e. batch size = 2),the second of which is a mirrored version of
the first.</p>
<p>Arguments:
cameras -- list of cameras, one element for each video
    (optional, used for semi-supervised training)</p>
<p>poses_3d -- list of ground-truth 3D poses, one element for each video
    (optional, used for supervised training)</p>
<p>poses_2d -- list of input 2D keypoints, one element for each video</p>
<p>pad -- 2D input padding to compensate for valid convolutions,
    per side (depends on the receptive field)</p>
<p>causal_shift -- asymmetric padding offset when causal convolutions
    are used (usually 0 or "pad")</p>
<p>augment -- augment the dataset by flipping poses horizontally</p>
<p>kps_left and kps_right -- list of left/right 2D keypoints if
    flipping is enabled</p>
<p>joints_left and joints_right -- list of left/right 3D joints if
    flipping is enabled</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

