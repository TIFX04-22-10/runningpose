{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "> Temporal dilated convolutional model.\n",
    "\n",
    "Our model is fully convolutional architechture with residual connections \n",
    "that takes a sequence of 2D poses as input and transforms them to 3D \n",
    "through temporal convolutions. Temporal means \"relating to time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TemporalModelBase(nn.Module):\n",
    "    \"\"\"Do not instantiate this class. This class is for inheritance.\"\"\"\n",
    "    def __init__(\n",
    "            self, num_joints_in, in_features, \n",
    "            num_joints_out, filter_witdhs, causal, dropout, channels):\n",
    "        super().__init__()\n",
    "        # Validate filter (Kernals) witdh input.\n",
    "        for fw in filter_witdhs:\n",
    "            assert fw % 2 != 0, \"Only odd filter widths are supported.\"\n",
    "\n",
    "        self.num_joints_in = num_joints_in\n",
    "        self.in_features = in_features\n",
    "        self.num_joints_out = num_joints_out\n",
    "        self.filter_widths = filter_witdhs\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU(inplace=True) \n",
    "        \n",
    "        # Makes output the same size as the input after going through filter.\n",
    "        self.pad = [filter_witdhs[0] // 2]  \n",
    "\n",
    "        self.expand_bn = nn.BatchNorm1d(channels, momentum=0.1) \n",
    "        self.shrink = nn.Conv1d(channels, num_joints_in*3, 1)\n",
    "        \n",
    "    def set_bn_momentum(self, momentum):\n",
    "        \"\"\"\n",
    "        Sets the batch norm momentum and updates the \n",
    "        corresponding layers where it is used.\n",
    "        \"\"\"\n",
    "        self.expand_bn = momentum\n",
    "        for bn in self.layers_bn: \n",
    "            bn.momentum = momentum\n",
    "\n",
    "    def receptive_field(self):\n",
    "        \"\"\"Return the total receptive field of this model as number of frames.\"\"\"\n",
    "        frames = 0\n",
    "        for f in self.pad:\n",
    "            frames += f\n",
    "        return 1 + 2*frames\n",
    "\n",
    "    def total_causal_shift(self):\n",
    "        \"\"\"\n",
    "        Return the asymmetric offset for sequence padding.\n",
    "        The returned value is typically 0 if causal convolutions are \n",
    "        disabled, otherwise it is half the receptive field.\n",
    "        Causal convolutions ensures the model cannot violate the \n",
    "        ordering in which we model the temporal data. \n",
    "        \"\"\"\n",
    "        frames = self.causal_shift[0]\n",
    "        next_dilation = self.filter_widths[0]\n",
    "        for i in range(1, len(self.filter_widths)):\n",
    "            frames += self.causal_shift[i] * next_dilation\n",
    "            next_dilation *=self.filter_widths[i]\n",
    "        return frames\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4\n",
    "        assert x.shape[-2] == self.num_joints_in\n",
    "        assert x.shape[-1] == self.in_features\n",
    "\n",
    "        sz = x.shape[:3]\n",
    "        x = x.view(x.shape[0], x.shape[1], -1)  \n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self._forward_blocks(x) \n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = x.view(sz[0], -1, self.num_joints_out, 3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 2, 12])\n",
      "torch.Size([1, 12, 2])\n",
      "torch.Size([1, 2, 12])\n",
      "torch.Size([1, 2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# To better understand what happens in the forward pass above.\n",
    "import torch\n",
    "x = torch.randn(1, 2, 3, 4)\n",
    "print(x.shape)\n",
    "sz = x.shape[:3]\n",
    "print(sz)\n",
    "x = x.view(x.shape[0], x.shape[1], -1) # reshapes the tensor\n",
    "print(x.shape)\n",
    "x = x.permute(0, 2, 1)\n",
    "print(x.shape)\n",
    "\n",
    "# Then it goes through the other _foward_blocks returns x. \n",
    "x = x.permute(0, 2, 1)\n",
    "print(x.shape)\n",
    "# Assuming num_joints_out = 4 \n",
    "x = x.view(sz[0], -1, 4, 3)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class TemporalModel(TemporalModelBase):\n",
    "    \"\"\"3D pose estimation model with temporal convolutions.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, num_joints_in, in_features, num_joints_out, filter_widths, \n",
    "            causal=False, dropout=0.25, channels=1024, dense=False):\n",
    "        \"\"\"\n",
    "        Initialize the temporal model.\n",
    "\n",
    "        Arguments:\n",
    "        num_joints_in -- Number of input joints to our model. \n",
    "        in_features -- Number of input features for each joint.\n",
    "        num_joints_out -- Number of output joints (can be different than input).\n",
    "\n",
    "        filter_widths -- List of convolutions, \n",
    "            which also determines the number of blocks and receptive field.\n",
    "\n",
    "        causal -- Use causal convolutions instead of symmetric \n",
    "            convolutions (for real-time applications).\n",
    "    \n",
    "        dropout -- Dropout probability.\n",
    "        channels -- Number of convolution channels.\n",
    "\n",
    "        dense -- Use regular dense convolutions instead of dilated \n",
    "            convolutions (ablation experiment).\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(num_joints_in, in_features, num_joints_out, \n",
    "                         filter_widths, causal, dropout, channels)                  \n",
    "        self.expand_conv = nn.Conv1d(num_joints_in*in_features, \n",
    "                                     channels, filter_widths[0], bias=False)\n",
    "        self.causal_shift = [(filter_widths[0] // 2) if causal else 0] \n",
    "\n",
    "        # Initialize and build layers and the stores them in a list.\n",
    "        layers_conv = []\n",
    "        layers_bn = []\n",
    "        next_dilation = filter_widths[0]\n",
    "        for i in range(1, len(filter_widths)):\n",
    "            self.pad.append((filter_widths[i] - 1)*next_dilation // 2 )\n",
    "            self.causal_shift.append(\n",
    "                (filter_widths[i]//2 * next_dilation) if causal else 0)\n",
    "\n",
    "            layers_conv.append(nn.Conv1d(\n",
    "                channels, channels, \n",
    "                filter_widths[i] if not dense else (2*self.pad[-1] + 1),\n",
    "                dilation=next_dilation if not dense else 1, bias=False))\n",
    "\n",
    "            layers_bn.append(nn.BatchNorm1d(channels, momentum=0.1))\n",
    "            layers_conv.append(nn.Conv1d(\n",
    "                channels, channels, 1, dilation=1, bias=False))\n",
    "            layers_bn.append(nn.BatchNorm1d(channels, momentum=0.1))\n",
    "\n",
    "            next_dilation *= filter_widths[i]\n",
    "\n",
    "        # Add to a ModuleList that holds submodules visible by all Module methods.\n",
    "        self.layers_conv = nn.ModuleList(layers_conv)\n",
    "        self.layers_bn = nn.ModuleList(layers_bn)\n",
    "\n",
    "    def _forward_blocks(self, x):\n",
    "        x = self.drop(self.relu(self.expand_bn(self.expand_conv(x))))\n",
    "        \n",
    "        for i in range(len(self.pad) - 1):\n",
    "            pad = self.pad[i+1]\n",
    "            shift = self.causal_shift[i+1]\n",
    "            res = x[:, :, pad + shift : x.shape[2] - pad + shift]\n",
    "            x = self.drop(self.relu(\n",
    "                self.layers_bn[2*i](self.layers_conv[2*i](x))))\n",
    "            x = res + self.drop(self.relu(\n",
    "                self.layers_bn[2*i + 1](self.layers_conv[2*i + 1](x))))\n",
    "        \n",
    "        # Fits the last layer so that it matches our output preferences.\n",
    "        x = self.shrink(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_loss.ipynb.\n",
      "Converted 02_skeleton.ipynb.\n",
      "Converted 03_mocap_dataset.ipynb.\n",
      "Converted 04_h36m_dataset.ipynb.\n",
      "Converted 05_camera.ipynb.\n",
      "Converted 06_quaternion.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_generators.ipynb.\n",
      "Converted 09_custom_dataset.ipynb.\n",
      "Converted 10_visualization.ipynb.\n",
      "Converted 11_arguments.ipynb.\n",
      "Converted 12_data_utils.ipynb.\n",
      "Converted 13_prepare_data_2d_custom.ipynb.\n",
      "Converted 14_infer_video.ipynb.\n",
      "Converted 15_prepare_data_COCO.ipynb.\n",
      "Converted 16_pycococreatortools.ipynb.\n",
      "Converted 17_format_qtmdata.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fastai')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
