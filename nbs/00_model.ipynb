{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "> Temporal dilated convolutional model.\n",
    "\n",
    "Our model is fully convolutional architechture with residual connections that takes a sequence of 2D poses as input and transforms them to 3D through temporal convolutions. Temporal means \"relating to time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TemporalModelBase(nn.Module):\n",
    "    \"\"\"Do not instantiate this class. This class is for inheritance.\"\"\"\n",
    "    def __init__(self, num_joints_in, in_features, num_joints_out, filter_witdhs, causal, dropout, channels):\n",
    "        super().__init__()\n",
    "        # Validate filter (Kernals) witdh input.\n",
    "        for fw in filter_witdhs:\n",
    "            assert fw % 2 != 0, \"Only odd filter widths are supported.\"\n",
    "\n",
    "        self.num_joints_in = num_joints_in\n",
    "        self.in_features = in_features\n",
    "        self.num_joints_out = num_joints_out\n",
    "        self.filter_widths = filter_witdhs\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "         \n",
    "        self.pad = [filter_witdhs[0] // 2] # Pad size that makes output the same size as the input after going through filter. \n",
    "        self.expand_bn = nn.BatchNorm1d(channels, momentum=0.1) \n",
    "        self.shrink = nn.Conv1d(channels, num_joints_in*3, 1)\n",
    "        \n",
    "    def set_bn_momentum(self, momentum):\n",
    "        \"\"\"Sets the batch norm momentum and updates the corresponding layers where it is used.\"\"\"\n",
    "        self.expand_bn = momentum\n",
    "        for bn in self.layers_bn: \n",
    "            bn.momentum = momentum\n",
    "\n",
    "    def receptive_field(self):\n",
    "        \"\"\"Return the total receptive field of this model as number of frames.\"\"\"\n",
    "        frames = 0\n",
    "        for f in self.pad:\n",
    "            frames += f\n",
    "        return 1 + 2*frames\n",
    "\n",
    "    def total_causal_shift(self):\n",
    "        \"\"\"\n",
    "        Return the asymmetric offset for sequence padding.\n",
    "        The returned value is typically 0 if causal convolutions are disabled,\n",
    "        otherwise it is half the receptive field.\n",
    "        Causal convolutions ensures the model cannot violate the ordering in which we model the temporal data. \n",
    "        \"\"\"\n",
    "        frames = self.causal_shift[0]\n",
    "        next_dilation = self.filter_widths[0]\n",
    "        for i in range(1, len(self.filter_widths)):\n",
    "            frames += self.causal_shift[i] * next_dilation\n",
    "            next_dilation *=self.filter_widths[i]\n",
    "        return frames\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4 # [~, ~, num_joints_in, in_features]\n",
    "        assert x.shape[-2] == self.num_joints_in\n",
    "        assert x.shape[-1] == self.in_features\n",
    "\n",
    "        sz = x.shape[:3]\n",
    "        x = x.view(x.shape[0], x.shape[1], -1)  # The size -1 is inferred from other dimensions.\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self._forward_blocks(x) # Creates a forward block that subclasses implement.\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = x.view(sz[0], -1, self.num_joints_out, 3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2, 1])\n",
      "torch.Size([1, 2, 3, 4])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 4, 2, 3])\n",
      "torch.Size([2, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# To better understand what happens in the forward pass above.\n",
    "import torch\n",
    "x = torch.randn(1, 2, 3, 4)\n",
    "print(x.permute(3, 2, 1, 0).shape)\n",
    "print(x.shape)\n",
    "sz = x.shape[:3]\n",
    "print(sz)\n",
    "x = x.view(sz[0], -1, 2, 3) # the size -1 is inferred from other dimensions\n",
    "y = x.view(sz[1], -1, 2, 3)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class TemporalModel(TemporalModelBase):\n",
    "    \"\"\"3D pose estimation model with temporal convolutions.\"\"\"\n",
    "\n",
    "    def __init__(self, num_joints_in, in_features, num_joints_out, filter_widths, causal=False, dropout=0.25,\n",
    "                 channels=1024,   dense=False):\n",
    "        \"\"\"\n",
    "        Initialize the temporal model.\n",
    "\n",
    "        Arguments:\n",
    "        num_joints_in -- Number of input joints to our model. \n",
    "        in_features -- Number of input features for each joint (typically 2 for 2D input).\n",
    "        num_joints_out -- Number of output joints (can be different than input).\n",
    "        filter_widths -- List of convolutions, which also determines the number of blocks and receptive field.\n",
    "        causal -- Use causal convolutions instead of symmetric convolutions (for real-time applications).\n",
    "        dropout -- Dropout probability.\n",
    "        channels -- Number of convolution channels. \n",
    "        dense -- Use regular dense convolutions instead of dilated convolutions (ablation experiment).\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(num_joints_in, in_features, num_joints_out, filter_widths, causal, dropout, channels)\n",
    "        self.expand_conv = nn.Conv1d(num_joints_in*in_features, channels, filter_widths[0], bias=False)\n",
    "        self.causal_shift = [ (filter_widths[0] // 2) if causal else 0 ] \n",
    "\n",
    "        # Initialize and build layers and the stores them in a list.\n",
    "        layers_conv = []\n",
    "        layers_bn = []\n",
    "        next_dilation = filter_widths[0]\n",
    "        for i in range(1, len(filter_widths)):\n",
    "            self.pad.append((filter_widths[i] - 1)*next_dilation // 2 )\n",
    "            self.causal_shift.append((filter_widths[i]//2 * next_dilation) if causal else 0)\n",
    "\n",
    "            layers_conv.append(nn.Conv1d(channels, channels, filter_widths[i] if not dense else (2*self.pad[-1] + 1),\n",
    "                                         dilation=next_dilation if not dense else 1, bias=False)) \n",
    "            layers_bn.append(nn.BatchNorm1d(channels, momentum=0.1))\n",
    "            layers_conv.append(nn.Conv1d(channels, channels, 1, dilation=1, bias=False))\n",
    "            layers_bn.append(nn.BatchNorm1d(channels, momentum=0.1))\n",
    "\n",
    "            next_dilation *= filter_widths[i]\n",
    "\n",
    "        # Add the lists to a ModuleList that holds submodules visible by all Module methods.\n",
    "        self.layers_conv = nn.ModuleList(layers_conv)\n",
    "        self.layers_bn = nn.ModuleList(layers_bn)\n",
    "\n",
    "    def _forward_blocks(self, x):\n",
    "        x = self.drop(self.relu(self.expand_bn(self.expand_conv(x))))\n",
    "        \n",
    "        for i in range(len(self.pad) - 1):\n",
    "            pad = self.pad[i+1]\n",
    "            shift = self.causal_shift[i+1]\n",
    "            res = x[:, :, pad + shift : x.shape[2] - pad + shift]\n",
    "            x = self.drop(self.relu(self.layers_bn[2*i](self.layers_conv[2*i](x))))\n",
    "            x = res + self.drop(self.relu(self.layers_bn[2*i + 1](self.layers_conv[2*i + 1](x))))\n",
    "        \n",
    "        # Fits the last layer so that it matches our output preferences.\n",
    "        x = self.shrink(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fastai')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
