{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators\n",
    "> Data generators for training and testing respectively.\n",
    "\n",
    "Generators are iterators, a kind of iterable **you can only iterate over once.** Generators do not store all the values in memory, **they generate values on the fly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from itertools import zip_longest\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ChunkedGenerator:\n",
    "    \"\"\"\n",
    "    Batched data generator, used for training.\n",
    "    The sequences are split into equal-length chunks and padded as necessary.\n",
    "    \n",
    "    Arguments:\n",
    "    batch_size -- The batch size to use for training.\n",
    "    cameras -- List of cameras, one element for each video \n",
    "        (optional, used for semi-supervised training).\n",
    "\n",
    "    poses_3d -- List of ground-truth 3D poses, one element for each video \n",
    "        (optional, used for supervised training).\n",
    "\n",
    "    poses_2d -- List of input 2D keypoints, one element for each video.\n",
    "\n",
    "    chunk_length -- Number of output frames to predict for each training \n",
    "        example (usually 1).\n",
    "\n",
    "    pad -- 2D input padding to compensate for valid convolutions, \n",
    "        per side (depends on the receptive field).\n",
    "\n",
    "    causal_shift -- Asymmetric padding offset when causal convolutions\n",
    "         are used (usually 0 or \"pad\").\n",
    "    shuffle -- Randomly shuffle the dataset before each epoch.\n",
    "    random_seed -- Initial seed to use for the random generator.\n",
    "    augment -- Augment the dataset by flipping poses horizontally.\n",
    "    \n",
    "    kps_left and kps_right -- List of left/right 2D keypoints if \n",
    "        flipping is enabled.\n",
    "\n",
    "    joints_left and joints_right -- List of left/right 3D joints if \n",
    "        flipping is enabled.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, batch_size, cameras, poses_3d, poses_2d, chunk_length, pad=0,  \n",
    "            causal_shift=0, shuffle=True,random_seed=47, augment=False, \n",
    "            kps_left=None, kps_right=None, joints_left=None, \n",
    "            joints_right=None, endless=False):\n",
    "                    \n",
    "        assert poses_3d is None or len(poses_3d) == len(poses_2d), \"Number of 3D poses and 2D poses differ.\"\n",
    "        assert cameras is None or len(cameras) == len(poses_2d)\n",
    "\n",
    "        # Build lineage info\n",
    "        pairs = [] # (seq_idx, start_frame, end_frame, flip) tuples\n",
    "        for i in range(len(poses_2d)):\n",
    "            n_chunks = (poses_2d[i].shape[0] + chunk_length - 1) // chunk_length\n",
    "            offset = (n_chunks * chunk_length - poses_2d[i].shape[0]) // 2\n",
    "            bounds = np.arange(n_chunks+1)*chunk_length - offset\n",
    "            augment_vector = np.full(len(bounds - 1), False, dtype=bool)\n",
    "            pairs += zip(np.repeat(\n",
    "                i, len(bounds - 1)), bounds[:-1], bounds[1:], augment_vector)\n",
    "            if augment:\n",
    "                pairs += zip(np.repeat(\n",
    "                    i, len(bounds - 1)), bounds[:-1], bounds[1:], ~augment_vector)\n",
    "\n",
    "        # Initialize buffers\n",
    "        if cameras is not None:\n",
    "            self.batch_cam = np.empty((batch_size, cameras[0].shape[-1]))\n",
    "        if poses_3d is not None:\n",
    "            self.batch_3d = np.empty((\n",
    "                batch_size, chunk_length, \n",
    "                poses_3d[0].shape[-2], poses_3d[0].shape[-1]\n",
    "            ))\n",
    "        self.batch_2d = np.empty((\n",
    "            batch_size, chunk_length + 2*pad, \n",
    "            poses_2d[0].shape[-2], poses_2d[0].shape[-1]\n",
    "        ))\n",
    "\n",
    "        # Initialize instance variables.\n",
    "        self.num_batches = (len(pairs) + batch_size - 1) // batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.random = np.random.RandomState(random_seed)\n",
    "        self.pairs = pairs\n",
    "        self.shuffle = shuffle\n",
    "        self.pad = pad\n",
    "        self.causal_shift = causal_shift\n",
    "        self.endless = endless\n",
    "        self.state = None\n",
    "        \n",
    "        self.cameras = cameras\n",
    "        self.poses_3d = poses_3d\n",
    "        self.poses_2d = poses_2d\n",
    "        \n",
    "        self.augment = augment\n",
    "        self.kps_left = kps_left\n",
    "        self.kps_right = kps_right\n",
    "        self.joints_left = joints_left\n",
    "        self.joints_right = joints_right\n",
    "\n",
    "    def num_frames(self):\n",
    "        \"\"\"Returns the total number of frames that we train on.\"\"\"\n",
    "        return self.num_batches * self.batch_size\n",
    "\n",
    "    def random_state(self):\n",
    "        \"\"\"Returns the random state used by the chunked generator.\"\"\"\n",
    "        return self.random\n",
    "\n",
    "    def set_random_state(self, random):\n",
    "        \"\"\"Sets the random state for the chunked generator.\"\"\"\n",
    "        self.random = random\n",
    "    \n",
    "    def augment_enabled(self):\n",
    "        \"\"\"Returns a boolean if we use data-augmentation or not.\"\"\"\n",
    "        return self.augment\n",
    "\n",
    "    def next_pairs(self):\n",
    "        \"\"\"Returns the next pairs or None. Can also shuffle the data.\"\"\"\n",
    "        if self.state is None:\n",
    "            if self.shuffle:\n",
    "                pairs = self.random.permutation(self.pairs)\n",
    "            else:\n",
    "                pairs = self.pairs\n",
    "            return 0, pairs\n",
    "        else:\n",
    "            return self.state\n",
    "    \n",
    "    def next_epoch(self):\n",
    "        \"\"\"\n",
    "        Sets up the next forward pass + backward pass for all the \n",
    "        training samples.\n",
    "        Returns (or yields) a generator object.\n",
    "        \"\"\"\n",
    "        enabled = True\n",
    "        while enabled:\n",
    "            start_idx, pairs = self.next_pairs()\n",
    "            for batch_index in range(start_idx, self.num_batches):\n",
    "                chunks = pairs[\n",
    "                    batch_index*self.batch_size : (batch_index+1)*self.batch_size\n",
    "                ]\n",
    "                for i, (seq_idx, start_3d, end_3d, flip) in enumerate(chunks):\n",
    "                    start_2d = start_3d - self.pad - self.causal_shift\n",
    "                    end_2d = end_3d + self.pad - self.causal_shift\n",
    "\n",
    "                    # 2D poses\n",
    "                    seq_2d = self.poses_2d[seq_idx]\n",
    "                    low_2d = max(start_2d, 0)\n",
    "                    high_2d = min(end_2d, seq_2d.shape[0])\n",
    "                    pad_left_2d = low_2d - start_2d\n",
    "                    pad_right_2d = end_2d - high_2d\n",
    "                    if pad_left_2d != 0 or pad_right_2d != 0:\n",
    "                        self.batch_2d[i] = np.pad(\n",
    "                            seq_2d[low_2d:high_2d], \n",
    "                            ((pad_left_2d, pad_right_2d), \n",
    "                            (0, 0), (0, 0)), 'edge'\n",
    "                        )\n",
    "                    else:\n",
    "                        self.batch_2d[i] = seq_2d[low_2d:high_2d]\n",
    "\n",
    "                    if flip:\n",
    "                        # Flip 2D keypoints\n",
    "                        self.batch_2d[i, :, :, 0] *= -1\n",
    "                        self.batch_2d[\n",
    "                            i, :, self.kps_left + self.kps_right\n",
    "                        ] = self.batch_2d[\n",
    "                            i, :, self.kps_right + self.kps_left\n",
    "                        ]\n",
    "\n",
    "                    # 3D poses\n",
    "                    if self.poses_3d is not None:\n",
    "                        seq_3d = self.poses_3d[seq_idx]\n",
    "                        low_3d = max(start_3d, 0)\n",
    "                        high_3d = min(end_3d, seq_3d.shape[0])\n",
    "                        pad_left_3d = low_3d - start_3d\n",
    "                        pad_right_3d = end_3d - high_3d\n",
    "                        if pad_left_3d != 0 or pad_right_3d != 0:\n",
    "                            self.batch_3d[i] = np.pad(\n",
    "                                seq_3d[low_3d:high_3d], \n",
    "                                ((pad_left_3d, pad_right_3d), \n",
    "                                (0, 0), (0, 0)), 'edge'\n",
    "                            )\n",
    "                        else:\n",
    "                            self.batch_3d[i] = seq_3d[low_3d:high_3d]\n",
    "\n",
    "                        if flip:\n",
    "                            # Flip 3D joints\n",
    "                            self.batch_3d[i, :, :, 0] *= -1\n",
    "                            self.batch_3d[\n",
    "                                i, :, self.joints_left + self.joints_right\n",
    "                            ] = self.batch_3d[\n",
    "                                i, :, self.joints_right + self.joints_left\n",
    "                            ]           \n",
    "\n",
    "                    # Cameras\n",
    "                    if self.cameras is not None:\n",
    "                        self.batch_cam[i] = self.cameras[seq_idx]\n",
    "                        if flip:\n",
    "                            # Flip horizontal distortion coefficients\n",
    "                            self.batch_cam[i, 2] *= -1\n",
    "                            self.batch_cam[i, 7] *= -1\n",
    "\n",
    "                if self.endless:\n",
    "                    self.state = (batch_index + 1, pairs)\n",
    "                if self.poses_3d is None and self.cameras is None:\n",
    "                    yield None, None, self.batch_2d[:len(chunks)]\n",
    "                elif self.poses_3d is not None and self.cameras is None:\n",
    "                    yield None, self.batch_3d[:len(chunks)], self.batch_2d[:len(chunks)]\n",
    "                elif self.poses_3d is None:\n",
    "                    yield self.batch_cam[:len(chunks)], None, self.batch_2d[:len(chunks)]\n",
    "                else:\n",
    "                    yield self.batch_cam[:len(chunks)], self.batch_3d[:len(chunks)], self.batch_2d[:len(chunks)]\n",
    "\n",
    "            if self.endless:\n",
    "                self.state = None\n",
    "            else:\n",
    "                enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UnchunkedGenerator:\n",
    "    \"\"\"\n",
    "    Non-batched data generator, used for testing.\n",
    "    Sequences are returned one at a time (i.e. batch size = 1), \n",
    "    without chunking.\n",
    "    \n",
    "    If data augmentation is enabled, the batches contain two sequences \n",
    "    (i.e. batch size = 2),the second of which is a mirrored version of \n",
    "    the first.\n",
    "    \n",
    "    Arguments:\n",
    "    cameras -- list of cameras, one element for each video \n",
    "        (optional, used for semi-supervised training)\n",
    "\n",
    "    poses_3d -- list of ground-truth 3D poses, one element for each video \n",
    "        (optional, used for supervised training)\n",
    "\n",
    "    poses_2d -- list of input 2D keypoints, one element for each video\n",
    "\n",
    "    pad -- 2D input padding to compensate for valid convolutions, \n",
    "        per side (depends on the receptive field)\n",
    "\n",
    "    causal_shift -- asymmetric padding offset when causal convolutions \n",
    "        are used (usually 0 or \"pad\")\n",
    "\n",
    "    augment -- augment the dataset by flipping poses horizontally\n",
    "    \n",
    "    kps_left and kps_right -- list of left/right 2D keypoints if \n",
    "        flipping is enabled\n",
    "\n",
    "    joints_left and joints_right -- list of left/right 3D joints if \n",
    "        flipping is enabled\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, cameras, poses_3d, poses_2d, pad=0, causal_shift=0,\n",
    "            augment=False, kps_left=None, kps_right=None, \n",
    "            joints_left=None, joints_right=None):\n",
    "\n",
    "        assert poses_3d is None or len(poses_3d) == len(poses_2d)\n",
    "        assert cameras is None or len(cameras) == len(poses_2d)\n",
    "\n",
    "        self.augment = augment\n",
    "        self.kps_left = kps_left\n",
    "        self.kps_right = kps_right\n",
    "        self.joints_left = joints_left\n",
    "        self.joints_right = joints_right\n",
    "\n",
    "        self.pad = pad\n",
    "        self.causal_shift = causal_shift\n",
    "        self.cameras = [] if cameras is None else cameras\n",
    "        self.poses_3d = [] if poses_3d is None else poses_3d\n",
    "        self.poses_2d = poses_2d\n",
    "    \n",
    "    def num_frames(self):\n",
    "        \"\"\"Returns the total number of frames that we test on.\"\"\"\n",
    "        count = 0\n",
    "        for pose in self.poses_2d:\n",
    "            count += pose.shape[0]\n",
    "        return count \n",
    "    \n",
    "    def augment_enabled(self):\n",
    "        \"\"\"Returns a boolean if we use data augmentation or not.\"\"\"\n",
    "        return self.augment\n",
    "    \n",
    "    def set_augment(self, augment):\n",
    "        \"\"\"Turn on and turn off data augmentation.\"\"\"\n",
    "        self.augment = augment\n",
    "\n",
    "    def next_epoch(self):\n",
    "        \"\"\"\n",
    "        Sets up the next forward pass for all the test samples.\n",
    "        Returns (or yields) a generator object.\n",
    "        \"\"\"\n",
    "        \n",
    "        for seq_cam, seq_3d, seq_2d in zip_longest(\n",
    "                self.cameras, self.poses_3d, self.poses_2d):\n",
    "                \n",
    "            batch_cam = None if seq_cam is None else np.expand_dims(seq_cam, axis=0)\n",
    "            batch_3d = None if seq_3d is None else np.expand_dims(seq_3d, axis=0)\n",
    "            # a and b are help variables only.\n",
    "            a, b = self.pad + self.causal_shift, self.pad - self.causal_shift \n",
    "            batch_2d = np.expand_dims(np.pad(\n",
    "                seq_2d,((a, b), (0, 0), (0, 0)), 'edge'), axis=0\n",
    "            )\n",
    "\n",
    "        if self.augment:\n",
    "                # Append flipped version\n",
    "                if batch_cam is not None:\n",
    "                    batch_cam = np.concatenate((batch_cam, batch_cam), axis=0)\n",
    "                    batch_cam[1, 2] *= -1\n",
    "                    batch_cam[1, 7] *= -1\n",
    "                \n",
    "                if batch_3d is not None:\n",
    "                    batch_3d = np.concatenate((batch_3d, batch_3d), axis=0)\n",
    "                    batch_3d[1, :, :, 0] *= -1\n",
    "                    batch_3d[1, :, self.joints_left + self.joints_right] \\\n",
    "                         = batch_3d[1, :, self.joints_right + self.joints_left]\n",
    "                    \n",
    "                batch_2d = np.concatenate((batch_2d, batch_2d), axis=0)\n",
    "                batch_2d[1, :, :, 0] *= -1\n",
    "                batch_2d[1, :, self.kps_left + self.kps_right] \\\n",
    "                    = batch_2d[1, :, self.kps_right + self.kps_left]\n",
    "\n",
    "        yield batch_cam, batch_3d, batch_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_loss.ipynb.\n",
      "Converted 02_skeleton.ipynb.\n",
      "Converted 03_mocap_dataset.ipynb.\n",
      "Converted 04_h36m_dataset.ipynb.\n",
      "Converted 05_camera.ipynb.\n",
      "Converted 06_quaternion.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_generators.ipynb.\n",
      "Converted 09_custom_dataset.ipynb.\n",
      "Converted 10_visualization.ipynb.\n",
      "Converted 11_arguments.ipynb.\n",
      "Converted 12_data_utils.ipynb.\n",
      "Converted 13_prepare_data_2d_custom.ipynb.\n",
      "Converted 14_infer_video.ipynb.\n",
      "Converted 15_prepare_data_COCO.ipynb.\n",
      "Converted 16_pycococreatortools.ipynb.\n",
      "Converted 17_format_qtmdata.ipynb.\n",
      "Converted 18_runningpose_dataset.ipynb.\n",
      "Converted 19_train_detectron2.ipynb.\n",
      "Converted 20_transfer_model.ipynb.\n",
      "Converted 21_prepare_data_3d.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fastai')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
