{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.prepare_data_2d_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare custom 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "output_prefix_2d = 'data_2d_custom_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def decode(filename):\n",
    "    \"\"\"Decodes the 2D data and returns a list with a dictionary and the following metadata.\"\"\"\n",
    "    print('Processing {}'.format(filename))\n",
    "    data = np.load(filename, allow_pickle=True)\n",
    "    boundary_box = data['boxes']\n",
    "    key_points = data['keypoints']\n",
    "    metadata = data['metadata'].item()\n",
    "\n",
    "    results_boundary_box = []\n",
    "    results_key_points = []\n",
    "    for i in range(len(boundary_box)):\n",
    "        if len(boundary_box[i][1]) == 0 or len(key_points[i][1]) == 0:\n",
    "            # No bbox/keypoints detected for this frame -> will be interpolated.\n",
    "            # 4 bounding box coordinates.\n",
    "            results_boundary_box.append(np.full(4, np.nan, dtype=np.float32)) \n",
    "            # 17 COCO keypoints\n",
    "            results_key_points.append(np.full((17, 4), np.nan, dtype=np.float32))\n",
    "            continue\n",
    "        best_match = np.argmax(boundary_box[i][1][:, 4])\n",
    "        best_boundary_box = boundary_box[i][1][best_match, :4]\n",
    "        best_key_point = key_points[i][1][best_match].T.copy()\n",
    "        results_boundary_box.append(best_boundary_box)\n",
    "        results_key_points.append(best_key_point)\n",
    "    \n",
    "    boundary_box = np.array(results_boundary_box, dtype=np.float32)\n",
    "    key_points = np.array(results_key_points, dtype=np.float32)\n",
    "    key_points = key_points[:, :, :2] # Extract (x,y)\n",
    "\n",
    "    # Fix missing bboxes/keypoints by linear interpolation\n",
    "    mask = ~np.isnan(boundary_box[:, 0])\n",
    "    indices = np.arange(len(boundary_box))\n",
    "    for i in range(4):\n",
    "        boundary_box[:, i] = np.interp(\n",
    "            indices, indices[mask], boundary_box[mask, i]\n",
    "        )\n",
    "\n",
    "    for i in range(17):\n",
    "        for j in range(2):\n",
    "            key_points[:, i, j] = np.interp(\n",
    "                indices, indices[mask], key_points[mask, i, j]\n",
    "            )\n",
    "    \n",
    "    print('{} total frames processed'.format(len(boundary_box)))\n",
    "    print('{} frames were interpolated'.format(np.sum(~mask)))\n",
    "    print('----------')\n",
    "    \n",
    "    return [{\n",
    "        'start_frame': 0, # Inclusive\n",
    "        'end_frame': len(key_points), # Exclusive\n",
    "        'bounding_boxes': boundary_box,\n",
    "        'keypoints': key_points,\n",
    "    }], metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "coco_metadata = {\n",
    "    'layout_name': 'coco',\n",
    "    'num_joints': 17,\n",
    "    'keypoints_symmetry': [\n",
    "        [1, 3, 5, 7, 9, 11, 13, 15],\n",
    "        [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "h36m_metadata = {\n",
    "    'layout_name': 'h36m',\n",
    "    'num_joints': 17,\n",
    "    'keypoints_symmetry': [\n",
    "        [4, 5, 6, 11, 12, 13],\n",
    "        [1, 2, 3, 14, 15, 16],\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def suggest_metadata(name):\n",
    "    \"\"\"Returns the metadata for a specific dataset.\"\"\"\n",
    "    names = []\n",
    "    for metadata in [coco_metadata, h36m_metadata]:\n",
    "        if metadata['layout_name'] in name:\n",
    "            return metadata\n",
    "        names.append(metadata['layout_name'])\n",
    "    raise KeyError('Cannot infer keypoint layout from name \"{}\". Tried {}.'.format(name, names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False\n",
    "\n",
    "if __name__ == '__main__' and not IN_NOTEBOOK:\n",
    "    if os.path.basename(os.getcwd()) != 'data':\n",
    "        print('This script must be launched from the \"data\" directory')\n",
    "        exit(0)\n",
    "        \n",
    "    parser = argparse.ArgumentParser(description='Custom dataset creator')\n",
    "    parser.add_argument(\n",
    "        '-i', '--input', type=str, default='', \n",
    "        metavar='PATH', help='detections directory'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '-o', '--output', type=str, default='', \n",
    "        metavar='PATH', help='output suffix for 2D detections'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if not args.input:\n",
    "        print('Please specify the input directory')\n",
    "        exit(0)\n",
    "        \n",
    "    if not args.output:\n",
    "        print('Please specify an output suffix (e.g. detectron_pt_coco)')\n",
    "        exit(0)\n",
    "    \n",
    "    print('Parsing 2D detections from', args.input)\n",
    "    \n",
    "    metadata = suggest_metadata('coco')\n",
    "    metadata['video_metadata'] = {}\n",
    "    \n",
    "    output = {}\n",
    "    file_list = glob(args.input + '/*.npz')\n",
    "    for f in file_list:\n",
    "        canonical_name = os.path.splitext(os.path.basename(f))[0]\n",
    "        data, video_metadata = decode(f)\n",
    "        output[canonical_name] = {}\n",
    "        output[canonical_name]['custom'] = [data[0]['keypoints'].astype('float32')]\n",
    "        metadata['video_metadata'][canonical_name] = video_metadata\n",
    "\n",
    "    print('Saving...')\n",
    "    np.savez_compressed(\n",
    "        output_prefix_2d + args.output, positions_2d=output, metadata=metadata\n",
    "    )\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_loss.ipynb.\n",
      "Converted 02_skeleton.ipynb.\n",
      "Converted 03_mocap_dataset.ipynb.\n",
      "Converted 04_h36m_dataset.ipynb.\n",
      "Converted 05_camera.ipynb.\n",
      "Converted 06_quaternion.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_generators.ipynb.\n",
      "Converted 09_custom_dataset.ipynb.\n",
      "Converted 10_visualization.ipynb.\n",
      "Converted 11_arguments.ipynb.\n",
      "Converted 12_data_utils.ipynb.\n",
      "Converted 13_prepare_data_2d_custom.ipynb.\n",
      "Converted 14_infer_video.ipynb.\n",
      "Converted 15_prepare_data_COCO.ipynb.\n",
      "Converted 16_pycococreatortools.ipynb.\n",
      "Converted 17_format_qtmdata.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fastai')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
