{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.inference.infer_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Video\n",
    "> Perform inference on a single video or all videos with a certain extension (e.g., mp4) in a folder. Returns a dataset with predicted: 2D keypoints, and bounding boxes. Right now it is the COCO-keypoints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='End-to-end inference')\n",
    "    parser.add_argument(\n",
    "        '--cfg',\n",
    "        dest='cfg',\n",
    "        help='cfg model file (/path/to/model_config.yaml)',\n",
    "        default=None,\n",
    "        type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output-dir',\n",
    "        dest='output_dir',\n",
    "        help='directory for visualization pdfs (default: /tmp/infer_simple)',\n",
    "        default='/tmp/infer_simple',\n",
    "        type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--image-ext',\n",
    "        dest='image_ext',\n",
    "        help='image file name extension (default: mp4)',\n",
    "        default='mp4',\n",
    "        type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        'im_or_folder', help='image or folder of images', default=None\n",
    "    )\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit(1)\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_resolution(filename):\n",
    "    \"\"\"Returns the width and height for a given video file.\"\"\"\n",
    "    command = ['ffprobe', '-v', 'error', '-select_streams', 'v:0',\n",
    "               '-show_entries', 'stream=width,height', '-of', 'csv=p=0', filename]\n",
    "    pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=-1)\n",
    "    for line in pipe.stdout:\n",
    "        w, h = line.decode().strip().split(',')\n",
    "        return int(w), int(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_video(filename):\n",
    "    \"\"\"Loads a given video file and returns it as a data generator.\"\"\"\n",
    "    w, h = get_resolution(filename)\n",
    "\n",
    "    command = ['ffmpeg',\n",
    "            '-hide_banner',\n",
    "            '-i', filename,\n",
    "            '-f', 'image2pipe',\n",
    "            '-pix_fmt', 'bgr24',\n",
    "            '-vsync', '0',\n",
    "            '-vcodec', 'rawvideo', '-']\n",
    "\n",
    "    pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=-1)\n",
    "    while True:\n",
    "        data = pipe.stdout.read(w*h*3)\n",
    "        if not data:\n",
    "            break\n",
    "        yield np.frombuffer(data, dtype='uint8').reshape((h, w, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Runs inference on the video files and saves the dataset in .npz file format.\n",
    "    Predicts the boundary box and the coco keypoints. \n",
    "    \"\"\"\n",
    "    # Create a detectron2 config and a detectron2 DefaultPredictor to run inference on video.\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(args.cfg))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_TRESH_TEST = 0.7 # Set threshold for this model.\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(args.cfg) \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    # Load the video folder in which we should predict.\n",
    "    if os.path.isdir(args.im_or_folder):\n",
    "        im_list = glob.iglob(args.im_or_folder + '/*.' + args.image_ext)\n",
    "    else:\n",
    "        im_list = [args.im_or_folder]\n",
    "\n",
    "    for video_name in im_list:\n",
    "        out_name = os.path.join(args.output_dir, os.path.basename(video_name))\n",
    "        print(\"Processing {}\".format(video_name))\n",
    "\n",
    "        # Initialize results:\n",
    "        boundary_boxes = []\n",
    "        segments = [] # Sets to None.\n",
    "        keypoints = []\n",
    "        for frame_i, im in enumerate(read_video(video_name)):\n",
    "            t = time.time()\n",
    "            outputs = predictor(im)['instances'].to('cpu')\n",
    "            print(\"Frame {} processed in {:.3f}s\".format(frame_i, time.time()-t)) \n",
    "            \n",
    "            # Checks if image is \"empty or not\".\n",
    "            has_bbox = False \n",
    "            if outputs.has('pred_boxes'):\n",
    "                bbox_tensor = outputs.pred_boxes.tensor.numpy()\n",
    "                if len(bbox_tensor) > 0:\n",
    "                    has_bbox = True\n",
    "                    scores = outputs.scores.numpy()[:, None]\n",
    "                    bbox_tensor = np.concatenate((bbox_tensor, scores), axis=1)\n",
    "            \n",
    "            if has_bbox:\n",
    "                kps = outputs.pred_keypoints.numpy()\n",
    "                kps_xy = kps[:, :, :2]\n",
    "                kps_prob = kps[:, :, 2:3]\n",
    "                kps_logit = np.zeros_like(kps_prob) # Dummy variable.\n",
    "                kps = np.concatenate((kps_xy, kps_logit, kps_prob), axis=2)\n",
    "                kps = kps.transpose(0, 2, 1)\n",
    "            else:\n",
    "                kps = []\n",
    "                bbox_tensor = []\n",
    "\n",
    "            # Mimic Detectron1 format\n",
    "            cls_boxes = [[], bbox_tensor]\n",
    "            cls_keyps = [[], kps]\n",
    "\n",
    "            boundary_boxes.append(cls_boxes)\n",
    "            segments.append(None)\n",
    "            keypoints.append(cls_keyps)\n",
    "        \n",
    "        # Video resolution.\n",
    "        metadata = {\n",
    "            'w': im.shape[1],\n",
    "            'h': im.shape[0],\n",
    "        }\n",
    "        \n",
    "        np.savez_compressed(out_name, boxes=boundary_boxes, segments=segments, keypoints=keypoints, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False\n",
    "\n",
    "if __name__ == '__main__' and not IN_NOTEBOOK:\n",
    "    setup_logger()\n",
    "    args = parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_loss.ipynb.\n",
      "Converted 02_skeleton.ipynb.\n",
      "Converted 03_mocap_dataset.ipynb.\n",
      "Converted 04_h36m_dataset.ipynb.\n",
      "Converted 05_camera.ipynb.\n",
      "Converted 06_quaternion.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_generators.ipynb.\n",
      "Converted 09_custom_dataset.ipynb.\n",
      "Converted 10_visualization.ipynb.\n",
      "Converted 11_arguments.ipynb.\n",
      "Converted 12_data_utils.ipynb.\n",
      "Converted 13_prepare_data_2d_custom.ipynb.\n",
      "Converted 14_infer_video.ipynb.\n",
      "Converted 15_prepare_data_COCO.ipynb.\n",
      "Converted 16_pycococreatortools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('poseai')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
