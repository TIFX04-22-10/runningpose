{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.format_qtmdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format qtmdata\n",
    ">  Format the Qualisys sports data preprocessed from Matlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)\n",
    "\n",
    "from core.camera import project_point_radial\n",
    "from core.runningpose_dataset import runningpose_cameras_extrinsic_params, runningpose_cameras_intrinsic_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Reformat qtmdata so that we can train.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--data-file', \n",
    "        dest='data_file',\n",
    "        help='qtm text file that has been formated in matlab', \n",
    "        type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output-dir',\n",
    "        dest='output_dir',\n",
    "        help='directory for reformated keypoint data (default: ./)',\n",
    "        default='./',\n",
    "        type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--cut-frame',\n",
    "        dest='cut_frame',\n",
    "        help='input what frame to cut the dataframe at.',\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--camera',\n",
    "        dest='camera',\n",
    "        help='which misqus camera (1, 2, 3) to use in runningpose dataset',\n",
    "        type=int,\n",
    "        choices=range(1, 4)\n",
    "    )\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def convert_to_2D(data_3D, camera_num):\n",
    "    \"\"\"Returns the corresponding 2D list for a 3D dataframe\"\"\"\n",
    "    # Get camera parameters.\n",
    "    R = runningpose_cameras_extrinsic_params[camera_num]['rotation']\n",
    "    T = np.array([runningpose_cameras_extrinsic_params[camera_num]['translation']]).T\n",
    "    # Choose fx as the focal length since in theory fx and fy should be equal. \n",
    "    f = runningpose_cameras_intrinsic_params[camera_num]['focal_length'][0]\n",
    "    c = np.array([runningpose_cameras_intrinsic_params[camera_num]['center']]).T\n",
    "    k = runningpose_cameras_intrinsic_params[camera_num]['radial_distortion']\n",
    "    p = runningpose_cameras_intrinsic_params[camera_num]['tangential_distortion']\n",
    "    # Extract a keypoint column and calculate it to 2D.\n",
    "    data_2D = []  \n",
    "    for column in data_3D:\n",
    "        col_data = data_3D[column].values\n",
    "        x_data = col_data[0::3]\n",
    "        y_data = col_data[1::3]\n",
    "        z_data = col_data[2::3]\n",
    "        data_world = np.array([x_data, y_data, z_data]).T\n",
    "        Proj, _, _, _, _ = project_point_radial(data_world, R, T, f, c, k, p)\n",
    "        data_2D.append(Proj)\n",
    "    \n",
    "    # TODO: Update so it returns a dataframe instead of a list. \n",
    "    # Get column names from input data_3D. \n",
    "    # TODO: Check the einsum in project_point_radial one more time. \n",
    "    return data_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# Loads the textfiles\n",
    "labels_np = np.loadtxt('updated_labels.txt', dtype = 'str')\n",
    "data_3D = np.loadtxt('Tindra1.txt', dtype = 'float', delimiter= ',')\n",
    "\n",
    "# Reformats the data to a dataframe\n",
    "data_3D = pd.DataFrame(data_3D, index=labels_np).T\n",
    "\n",
    "# Removes every other frame (3 rows corresponds to 1 frame.)\n",
    "remove = True\n",
    "for i in range(0, data_3D.shape[0]):\n",
    "    if i % 3 == 0:\n",
    "        remove = not(remove)\n",
    "\n",
    "    if remove:\n",
    "        data_3D = data_3D.drop(i)\n",
    "\n",
    "data_3D = data_3D.reset_index(drop=True)\n",
    "\n",
    "data_2D = convert_to_2D(data_3D, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "R = runningpose_cameras_extrinsic_params[0]['rotation']\n",
    "T = np.array([runningpose_cameras_extrinsic_params[0]['translation']]).T\n",
    "k = runningpose_cameras_intrinsic_params[0]['radial_distortion']\n",
    "c = np.array([runningpose_cameras_intrinsic_params[0]['center']]).T\n",
    "p = runningpose_cameras_intrinsic_params[0]['tangential_distortion']\n",
    "f = runningpose_cameras_intrinsic_params[0]['focal_length'][0]\n",
    "data_world = None\n",
    "for column in data_3D:\n",
    "    col_data = data_3D[column].values\n",
    "    x_data = col_data[0::3]\n",
    "    y_data = col_data[1::3]\n",
    "    z_data = col_data[2::3]\n",
    "    data_world = np.array([x_data, y_data, z_data]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343, 3)\n",
      "(2, 1)\n",
      "343\n",
      "(3, 343)\n",
      "(2, 343)\n",
      "(343,)\n",
      "[-0.045952, 0.137059, 0.0]\n",
      "(1, 1029)\n",
      "1029\n",
      "(3, 343)\n",
      "(1, 343)\n",
      "(343,)\n",
      "(2, 343)\n",
      "107467.257813\n",
      "(2, 343)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(data_world.shape)\n",
    "print(c.shape)\n",
    "N = data_world.shape[0]\n",
    "print(N)\n",
    "X = R.dot(data_world.T - T)\n",
    "print(X.shape)\n",
    "XX = X[:2,:] / X[2,:]\n",
    "print(XX.shape)\n",
    "r2 = XX[0,:]**2 + XX[1,:]**2\n",
    "print(r2.shape)\n",
    "print(k)\n",
    "A = np.tile(k, (1, N))\n",
    "print(A.shape)\n",
    "print(3*343)\n",
    "B = np.array([r2, r2**2, r2**3])\n",
    "print(B.shape)\n",
    "radial = 1 + np.einsum('ij,kl->il', np.tile(k,(1, N)), np.array([r2, r2**2, r2**3]))\n",
    "print(radial.shape)\n",
    "tan = p[0]*XX[1,:] + p[1]*XX[0,:]\n",
    "print(tan.shape)\n",
    "XXX = XX * np.tile(radial+tan,(2,1)) + np.outer(np.array([p[1], p[0]]).reshape(-1), r2)\n",
    "print(XXX.shape)\n",
    "print(f)\n",
    "\n",
    "Proj = (f * XXX) + c\n",
    "print(Proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Loads the qtm data then removes unwanted keypoints.\n",
    "    Then it infers new keypoints adds them. \n",
    "    Further we scale the dataset using a the norm vector between the \n",
    "    root and 'SpineThoracic2'. \n",
    "    \"\"\"\n",
    "    # Loads the textfiles\n",
    "    labels_np = np.loadtxt('qtm_labels.txt', dtype = 'str')\n",
    "    data_3D = np.loadtxt(args.data_file, dtype = 'float', delimiter= ',')\n",
    "\n",
    "    # Reformats the data to a dataframe\n",
    "    data_3D = pd.DataFrame(data_3D, index=labels_np).T\n",
    "\n",
    "    # Remove unwanted keypoints\n",
    "    data_3D = data_3D.drop(\n",
    "        columns=[\n",
    "            'HeadL', 'HeadR', 'Chest', 'LThighFrontLow', 'RThighFrontLow', \n",
    "            'LShinFrontHigh', 'RShinFrontHigh', 'LForefoot5', 'RForefoot5', \n",
    "            'LHeelBack', 'RHeelBack', 'LArm', 'RArm','WaistLFront', 'WaistL', \n",
    "            'WaistRFront', 'WaistR', 'LHand2', 'RHand2'\n",
    "        ]\n",
    "    )\n",
    "    # Create \"new\" keypoints by finding the mean between specific keypoints\n",
    "    left_elbow_3D = data_3D.loc[:, ['LElbowOut','LElbowIn']].mean(axis=1)\n",
    "    right_elbow_3D = data_3D.loc[:, ['RElbowOut','RElbowIn']].mean(axis=1)\n",
    "\n",
    "    left_wrist_3D = data_3D.loc[:, ['LWristIn','LWristOut']].mean(axis=1)\n",
    "    right_wrist_3D = data_3D.loc[:, ['RWristOut','RWristIn']].mean(axis=1)\n",
    "\n",
    "    left_knee_3D = data_3D.loc[:, ['LKneeOut','LKneeIn']].mean(axis=1)\n",
    "    right_knee_3D = data_3D.loc[:, ['RKneeOut','RKneeIn']].mean(axis=1)\n",
    "\n",
    "    left_ankle_3D = data_3D.loc[:, ['LAnkleOut','LAnkleIn']].mean(axis=1)\n",
    "    right_ankle_3D = data_3D.loc[:, ['RAnkleOut','RAnkleIn']].mean(axis=1)\n",
    "\n",
    "    # Remove the keypoints that was taken as a mean\n",
    "    data_3D = data_3D.drop(\n",
    "        columns=[\n",
    "            'LElbowOut','LElbowIn', 'RElbowOut','RElbowIn', \n",
    "            'LWristIn','LWristOut', 'RWristIn','RWristOut', \n",
    "            'LKneeIn', 'LKneeOut','RKneeIn', 'RKneeOut',\n",
    "            'LAnkleOut','LAnkleIn','RAnkleOut','RAnkleIn'\n",
    "        ]\n",
    "    )\n",
    "    # Adds the new keypoint data to the dataframe\n",
    "    data_3D['LElbow'] = left_elbow_3D\n",
    "    data_3D['RElbow'] = right_elbow_3D\n",
    "    data_3D['LWrist'] = left_wrist_3D\n",
    "    data_3D['RWrist'] = right_wrist_3D\n",
    "    data_3D['LKnee'] = left_knee_3D\n",
    "    data_3D['RKnee'] = right_knee_3D\n",
    "    data_3D['LAnkle'] = left_ankle_3D\n",
    "    data_3D['RAnkle'] = right_ankle_3D\n",
    "\n",
    "    # Remove every other frame, our videodata Miqus is 85hz and the data is 170hz\n",
    "    # OBS! (3 rows corresponds to 1 frame.)\n",
    "    remove = True\n",
    "    for i in range(0, data_3D.shape[0]):\n",
    "        if i % 3 == 0:\n",
    "            remove = not(remove)\n",
    "\n",
    "        if remove:\n",
    "            data_3D = data_3D.drop(i)\n",
    "    \n",
    "    data_3D = data_3D.reset_index(drop=True)\n",
    "\n",
    "    if args.cut_frame is not None:\n",
    "        # Cuts the data by the same frame as we cut the video. \n",
    "        data_3D = data_3D[:args.cut_frame]\n",
    "\n",
    "    # Convert 3D world to 2D camera coordinates\n",
    "    data_2D = convert_to_2D(data_3D, args.camera)\n",
    "\n",
    "    # Creates output names that depends on the name of the data file \n",
    "    data_file_name = os.path.basename(\n",
    "        os.path.normpath(args.data_file)).rsplit(\".\")[0]\n",
    "    out_2D = os.path.join(\n",
    "        args.output_dir, data_file_name + '_2D_keypoints.csv')\n",
    "    out_3D = os.path.join(\n",
    "        args.output_dir, data_file_name + '_3D_keypoints.csv')\n",
    "\n",
    "    # Save the keypoint data as csv files\n",
    "    # TODO: Add reformat to 2D data i.e 3DWorld -> 3DCamera -> 2D (projection)\n",
    "    # pd.DataFrame.to_csv(data_2D, path_or_buf=out_2D)\n",
    "    # TODO: Check if it is better to save this as npz instead. \n",
    "    pd.DataFrame.to_csv(data_3D, path_or_buf=out_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try: from nbdev.imports import IN_NOTEBOOK\n",
    "except: IN_NOTEBOOK=False\n",
    "\n",
    "if __name__ == '__main__' and not IN_NOTEBOOK:\n",
    "    args = parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_loss.ipynb.\n",
      "Converted 02_skeleton.ipynb.\n",
      "Converted 03_mocap_dataset.ipynb.\n",
      "Converted 04_h36m_dataset.ipynb.\n",
      "Converted 05_camera.ipynb.\n",
      "Converted 06_quaternion.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_generators.ipynb.\n",
      "Converted 09_custom_dataset.ipynb.\n",
      "Converted 10_visualization.ipynb.\n",
      "Converted 11_arguments.ipynb.\n",
      "Converted 12_data_utils.ipynb.\n",
      "Converted 13_prepare_data_2d_custom.ipynb.\n",
      "Converted 14_infer_video.ipynb.\n",
      "Converted 15_prepare_data_COCO.ipynb.\n",
      "Converted 16_pycococreatortools.ipynb.\n",
      "Converted 17_format_qtmdata.ipynb.\n",
      "Converted 18_runningpose_dataset.ipynb.\n",
      "Converted 19_train_detectron2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
