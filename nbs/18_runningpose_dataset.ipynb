{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.h36m_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runningpose Dataset\n",
    "> 3D human pose estimation dataset.\n",
    "\n",
    "For data collected for candidate project in cooperation with Qualisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import copy\n",
    "from runningpose.core.skeleton import Skeleton\n",
    "from runningpose.core.mocap_dataset import MocapDataset\n",
    "from runningpose.core.camera import normalize_screen_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RunningposeDataset(MocapDataset):\n",
    "    \"\"\"Runningpose pose estimation dataset.\"\"\"\n",
    "    def __init__(self, path):\n",
    "        super().__init__(fps=85, skeleton=runningpose_skeleton)\n",
    "        self.cameras = copy.deepcopy(runningpose_cameras_extrinsic_params)\n",
    "\n",
    "        for cameras in self._cameras.values():\n",
    "            for i, cam in enumerate(cameras):\n",
    "                cam.update(runningpose_cameras_intrinsic_params[i])\n",
    "                for k, v in cam.items():\n",
    "                    if k not in [\"id\", \"res_w\", \"res_h\"]:\n",
    "                        cam[k] = np.array(v, dtype='float32')\n",
    "        \n",
    "        # Normalize camera frame.\n",
    "        cam['center'] = normalize_screen_coordinates(\n",
    "            cam['center'], w=cam['res_w'], h=cam['res_h']).astype('float32')\n",
    "        cam['focal_length'] = cam['focal_length']/cam['res_w']*2\n",
    "        if 'translation' in cam:\n",
    "            cam['translation'] = cam['translation']/1000 # Milimeters to meters.  \n",
    "        # Add intrinsic parameters vector.\n",
    "        cam['intrinsic'] = np.concatenate(\n",
    "            (cam['focal_length'], cam['center'], \n",
    "            cam['radial_distortion'], cam['tangential_distortion']))\n",
    "\n",
    "        # Load serialized dataset.\n",
    "        data = np.load(path, allow_pickle=True)['positions_3d'].item() \n",
    "    \n",
    "        self._data = {}\n",
    "        for subject, actions in data.items():\n",
    "            self._data[subject] = {}\n",
    "            for action_name, positions in actions.items():\n",
    "                self._data[subject][action_name] = {\n",
    "                    'positions': positions,\n",
    "                    'cameras': self._cameras[subject],\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific parameters for the Human3.6M skeleton\n",
    "This is mainly to be consistent with other work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "runningpose_skeleton = Skeleton( #TODO: fix skeleton\n",
    "       parents=[\n",
    "              \n",
    "       ],\n",
    "       joints_left=[],\n",
    "       joints_right=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "runningpose_cameras_intrinsic_params = [\n",
    "    {\n",
    "        'id': 'miqusVideo1',\n",
    "        'center': [60818.726563, 32822.339844],\n",
    "        'focal_length': [107467.257813, 107467.640625],\n",
    "        'radial_distortion': [-0.045952, 0.137059, 0.000000],\n",
    "        'tangential_distortion': [0.000110, 0.000532],\n",
    "        'res_w': 1920,\n",
    "        'res_h': 1080,\n",
    "        'azimuth': 70, # Only used for visualization\n",
    "    },\n",
    "    {\n",
    "        'id': 'miqusVideo2',\n",
    "        'center': [61535.457031, 529684.667969],\n",
    "        'focal_length': [106897.671875, 106903.906250],\n",
    "        'radial_distortion': [-0.044311, 0.129243,0.000000],\n",
    "        'tangential_distortion': [0.000380, 0.000067],\n",
    "        'res_w': 1920,\n",
    "        'res_h': 1080,\n",
    "        'azimuth': 70, # Only used for visualization\n",
    "    },\n",
    "    {\n",
    "        'id': 'miqusVideo3',\n",
    "        'center': [60224.542969, 33399.539063],\n",
    "        'focal_length': [107180.078125, 107196.359375],\n",
    "        'radial_distortion': [-0.044245,0.134407, 0.000000],\n",
    "        'tangential_distortion': [0.000612, 0.000214],\n",
    "        'res_w': 1920,\n",
    "        'res_h': 1080,\n",
    "        'azimuth': 70, # Only used for visualization\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "runningpose_cameras_extrinsic_params = {\n",
    "    \"S\": [\n",
    "        {   # Miqus Video 1\n",
    "            'rotation': np.array([\n",
    "                [0.735354, 0.677463, 0.017256], \n",
    "                [-0.104186, 0.087855, 0.990670], \n",
    "                [0.669627, -0.730291, 0.135186]\n",
    "            ]),\n",
    "            'translation': [6643.345215, -2730.456543, 1153.752808],\n",
    "        },\n",
    "        {   # Miqus Video 2\n",
    "            'rotation': np.array([\n",
    "                [0.997871, -0.064902, 0.006349],\n",
    "                [-0.006020, 0.005255, 0.999968],\n",
    "                [-0.064933, -0.997878 , 0.004853]\n",
    "            ]),\n",
    "            'translation': [-697.331482, -2968.999268, 1121.579468],\n",
    "        },\n",
    "        {   # Miqus Video 3\n",
    "            'rotation': np.array([\n",
    "                [-0.641654, 0.766908, 0.011533],\n",
    "                [-0.137808, -0.130067, 0.981882],\n",
    "                [0.754513, 0.628438, 0.189144]\n",
    "            ]),\n",
    "            'translation': [14351.271484, 3795.722412, 1504.888672],\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_model.ipynb.\n",
      "Converted 01_loss.ipynb.\n",
      "Converted 02_skeleton.ipynb.\n",
      "Converted 03_mocap_dataset.ipynb.\n",
      "Converted 04_h36m_dataset.ipynb.\n",
      "Converted 05_camera.ipynb.\n",
      "Converted 06_quaternion.ipynb.\n",
      "Converted 07_utils.ipynb.\n",
      "Converted 08_generators.ipynb.\n",
      "Converted 09_custom_dataset.ipynb.\n",
      "Converted 10_visualization.ipynb.\n",
      "Converted 11_arguments.ipynb.\n",
      "Converted 12_data_utils.ipynb.\n",
      "Converted 13_prepare_data_2d_custom.ipynb.\n",
      "Converted 14_infer_video.ipynb.\n",
      "Converted 15_prepare_data_COCO.ipynb.\n",
      "Converted 16_pycococreatortools.ipynb.\n",
      "Converted 17_format_qtmdata.ipynb.\n",
      "Converted 18_runningpose_dataset.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
