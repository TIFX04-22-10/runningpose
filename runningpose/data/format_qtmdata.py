# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/17_format_qtmdata.ipynb (unless otherwise specified).

__all__ = ['currentdir', 'parentdir', 'parse_args', 'convert_to_2D', 'main']

# Cell
import numpy as np
import pandas as pd
import argparse
import os

import sys
import inspect

currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0, parentdir)

from core.camera import project_point_radial
from core.runningpose_dataset import runningpose_cameras_extrinsic_params, runningpose_cameras_intrinsic_params

# Cell
def parse_args():
    parser = argparse.ArgumentParser(
        description='Reformat qtmdata so that we can train.'
    )
    parser.add_argument(
        '--data-file',
        dest='data_file',
        help='qtm text file that has been formated in matlab',
        type=str
    )
    parser.add_argument(
        '--output-dir',
        dest='output_dir',
        help='directory for reformated keypoint data (default: ./)',
        default='./',
        type=str
    )
    parser.add_argument(
        '--cut-frame',
        dest='cut_frame',
        help='input what frame to cut the dataframe at.',
        type=int,
    )
    parser.add_argument(
        '--camera',
        dest='camera',
        help='which misqus camera (1, 2, 3) to use in runningpose dataset',
        type=int,
        choices=range(1, 4)
    )

    return parser.parse_args()

# Cell

def convert_to_2D(data_3D, camera_num):
    """Returns the corresponding 2D list for a 3D dataframe"""
    # Get camera parameters.
    R = runningpose_cameras_extrinsic_params[camera_num]['rotation']
    T = np.array([runningpose_cameras_extrinsic_params[camera_num]['translation']]).T
    # Choose fx as the focal length since in theory fx and fy should be equal.
    f = runningpose_cameras_intrinsic_params[camera_num]['focal_length'][0]
    c = np.array([runningpose_cameras_intrinsic_params[camera_num]['center']]).T
    k = runningpose_cameras_intrinsic_params[camera_num]['radial_distortion']
    p = runningpose_cameras_intrinsic_params[camera_num]['tangential_distortion']
    # Extract a keypoint column and calculate it to 2D.
    data_2D = []
    for column in data_3D:
        col_data = data_3D[column].values
        x_data = col_data[0::3]
        y_data = col_data[1::3]
        z_data = col_data[2::3]
        data_world = np.array([x_data, y_data, z_data]).T
        Proj, _, _, _, _ = project_point_radial(data_world, R, T, f, c, k, p) # Proj: Nx2 points in pixel space
        #data_2D.append(Proj) # this doesen't return correct dimensions

        # reform array [[x, x, x...], [y, y, y...]] to [x, y, x, y, x, y, x, y...]
        Proj_as_vector = []
        for i in range(len(Proj)):
            Proj_as_vector.append(Proj[i, 0])
            Proj_as_vector.append(Proj[i, 1])

        if len(data_2D) == 0:
            data_2D = Proj_as_vector # initialize with correct dim
        else:
            data_2D = np.vstack((data_2D, Proj_as_vector)) # check Proj correct keypoint format


    # Reformats the data to a dataframe
    data_2D = pd.DataFrame(data_2D, index=data_3D.columns).T

    # TODO: Check the einsum in project_point_radial one more time.
    # TODO: Check Proj format correctly restructured
    return data_2D

# Cell
def main(args):
    """
    Loads the qtm data then removes unwanted keypoints.
    Then it infers new keypoints adds them.
    Further we scale the dataset using a the norm vector between the
    root and 'SpineThoracic2'.
    """
    # Loads the textfiles
    labels_np = np.loadtxt('qtm_labels.txt', dtype = 'str')
    data_3D = np.loadtxt(args.data_file, dtype = 'float', delimiter= ',')

    # Reformats the data to a dataframe
    data_3D = pd.DataFrame(data_3D, index=labels_np).T

    # Remove unwanted keypoints
    data_3D = data_3D.drop(
        columns=[
            'HeadL', 'HeadR', 'Chest', 'LThighFrontLow', 'RThighFrontLow',
            'LShinFrontHigh', 'RShinFrontHigh', 'LForefoot5', 'RForefoot5',
            'LHeelBack', 'RHeelBack', 'LArm', 'RArm','WaistLFront', 'WaistL',
            'WaistRFront', 'WaistR', 'LHand2', 'RHand2'
        ]
    )
    # Create "new" keypoints by finding the mean between specific keypoints
    left_elbow_3D = data_3D.loc[:, ['LElbowOut','LElbowIn']].mean(axis=1)
    right_elbow_3D = data_3D.loc[:, ['RElbowOut','RElbowIn']].mean(axis=1)

    left_wrist_3D = data_3D.loc[:, ['LWristIn','LWristOut']].mean(axis=1)
    right_wrist_3D = data_3D.loc[:, ['RWristOut','RWristIn']].mean(axis=1)

    left_knee_3D = data_3D.loc[:, ['LKneeOut','LKneeIn']].mean(axis=1)
    right_knee_3D = data_3D.loc[:, ['RKneeOut','RKneeIn']].mean(axis=1)

    left_ankle_3D = data_3D.loc[:, ['LAnkleOut','LAnkleIn']].mean(axis=1)
    right_ankle_3D = data_3D.loc[:, ['RAnkleOut','RAnkleIn']].mean(axis=1)

    # Remove the keypoints that was taken as a mean
    data_3D = data_3D.drop(
        columns=[
            'LElbowOut','LElbowIn', 'RElbowOut','RElbowIn',
            'LWristIn','LWristOut', 'RWristIn','RWristOut',
            'LKneeIn', 'LKneeOut','RKneeIn', 'RKneeOut',
            'LAnkleOut','LAnkleIn','RAnkleOut','RAnkleIn'
        ]
    )
    # Adds the new keypoint data to the dataframe
    data_3D['LElbow'] = left_elbow_3D
    data_3D['RElbow'] = right_elbow_3D
    data_3D['LWrist'] = left_wrist_3D
    data_3D['RWrist'] = right_wrist_3D
    data_3D['LKnee'] = left_knee_3D
    data_3D['RKnee'] = right_knee_3D
    data_3D['LAnkle'] = left_ankle_3D
    data_3D['RAnkle'] = right_ankle_3D

    # Remove every other frame, our videodata Miqus is 85hz and the data is 170hz
    # OBS! (3 rows corresponds to 1 frame.)
    remove = True
    for i in range(0, data_3D.shape[0]):
        if i % 3 == 0:
            remove = not(remove)

        if remove:
            data_3D = data_3D.drop(i)

    data_3D = data_3D.reset_index(drop=True)

    if args.cut_frame is not None:
        # Cuts the data by the same frame as we cut the video.
        data_3D = data_3D[:args.cut_frame]

    # Convert 3D world to 2D camera coordinates
    data_2D = convert_to_2D(data_3D, args.camera-1) # args.camera-1 for cameras (0,1,2) instead of (1,2,3)

    # Creates output names that depends on the name of the data file
    data_file_name = os.path.basename(
        os.path.normpath(args.data_file)).rsplit(".")[0]
    out_2D = os.path.join(
        args.output_dir, data_file_name + '_2D_keypoints.csv')
    out_3D = os.path.join(
        args.output_dir, data_file_name + '_3D_keypoints.csv')



    # Save the keypoint data as csv files
    # TODO: Add reformat to 2D data i.e 3DWorld -> 3DCamera -> 2D (projection)
    # pd.DataFrame.to_csv(data_2D, path_or_buf=out_2D)
    # TODO: Check if it is better to save this as npz instead.
    pd.DataFrame.to_csv(data_3D, path_or_buf=out_3D)
    pd.DataFrame.to_csv(data_2D, path_or_buf=out_2D)

# Cell
try: from nbdev.imports import IN_NOTEBOOK
except: IN_NOTEBOOK=False

if __name__ == '__main__' and not IN_NOTEBOOK:
    args = parse_args()
    main(args)