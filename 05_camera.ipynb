{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera\n",
    "> A camera file with a range of functions to handle the camera and it's coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'runningpose.core.quaternion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22334/1554442740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrunningpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrunningpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquaternion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqrot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqinverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'runningpose.core.quaternion'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "from runningpose.core.utils import wrap\n",
    "from runningpose.core.quaternion import qrot, qinverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize_screen_coordinates(X, w, h): \n",
    "    \"\"\"Normalize so that [0, w] is mapped to [-1, 1], while preserving the aspect ratio.\"\"\"\n",
    "    assert X.shape[-1] == 2\n",
    "\n",
    "    return X/w*2 - [1, h/w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image_coordinates(X, w, h):\n",
    "    \"\"\"Return the image coordinates\"\"\"\n",
    "    assert X.shape[-1] == 2\n",
    "    # Reverse camera frame normalization\n",
    "    return (X + [1, h/w])*w/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def world_to_camera(X, R, t):\n",
    "    Rt = wrap(qinverse, R) # Invert rotation\n",
    "    return wrap(qrot, np.tile(Rt, (*X.shape[:-1], 1)), X - t) # Rotate and translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def camera_to_world(X, R, t):\n",
    "    return wrap(qrot, np.tile(R, (*X.shape[:-1], 1)), X) + t # Rotate and translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def project_to_2d(X, camera_params):\n",
    "    \"\"\"\n",
    "    Project 3D points to 2D using the Human3.6M camera projection function.\n",
    "    This is a differentiable and batched reimplementation of the original MATLAB script.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- 3D points in *camera space* to transform (N, *, 3)\n",
    "    camera_params -- intrinsic parameteres (N, 2+2+3+2=9)\n",
    "    \"\"\"\n",
    "    assert X.shape[-1] == 3\n",
    "    assert len(camera_params.shape) == 2\n",
    "    assert camera_params.shape[-1] == 9\n",
    "    assert X.shape[0] == camera_params.shape[0]\n",
    "    \n",
    "    while len(camera_params.shape) < len(X.shape):\n",
    "        camera_params = camera_params.unsqueeze(1)\n",
    "        \n",
    "    f = camera_params[..., :2]\n",
    "    c = camera_params[..., 2:4]\n",
    "    k = camera_params[..., 4:7]\n",
    "    p = camera_params[..., 7:]\n",
    "    \n",
    "    XX = torch.clamp(X[..., :2] / X[..., 2:], min=-1, max=1)\n",
    "    r2 = torch.sum(XX[..., :2]**2, dim=len(XX.shape)-1, keepdim=True)\n",
    "\n",
    "    radial = 1 + torch.sum(k * torch.cat((r2, r2**2, r2**3), dim=len(r2.shape)-1), dim=len(r2.shape)-1, keepdim=True)\n",
    "    tan = torch.sum(p*XX, dim=len(XX.shape)-1, keepdim=True)\n",
    "\n",
    "    XXX = XX*(radial + tan) + p*r2\n",
    "    \n",
    "    return f*XXX + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def project_to_2d_linear(X, camera_params):\n",
    "    \"\"\"\n",
    "    Project 3D points to 2D using only linear parameters (focal length and principal point).\n",
    "    \n",
    "    Arguments:\n",
    "    X -- 3D points in *camera space* to transform (N, *, 3)\n",
    "    camera_params -- intrinsic parameteres (N, 2+2+3+2=9)\n",
    "    \"\"\"\n",
    "    assert X.shape[-1] == 3\n",
    "    assert len(camera_params.shape) == 2\n",
    "    assert camera_params.shape[-1] == 9\n",
    "    assert X.shape[0] == camera_params.shape[0]\n",
    "    \n",
    "    while len(camera_params.shape) < len(X.shape):\n",
    "        camera_params = camera_params.unsqueeze(1)\n",
    "        \n",
    "    f = camera_params[..., :2]\n",
    "    c = camera_params[..., 2:4]\n",
    "    \n",
    "    XX = torch.clamp(X[..., :2] / X[..., 2:], min=-1, max=1)\n",
    "    \n",
    "    return f*XX + c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('fastai')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
